{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOhw2DJ5ky2+66YZIINfIwf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Training the ANN with Stochaistic Gradient Descent**\n","\n","- Step 1: Randomly initialise the weights to small numbers close to 0 (but not 0).\n","- Step 2: Input the first observation of your dataset in the input layer, each feature in one input mode. \n","- Step 3: *Forward-Propagation*: from left to right, the neurons are activated in a way that the impact of each neuron's activation is limited by the weights. Propagate the activations until getting the predicted result y.\n","- Step 4: Compare the predicted result to the actual result. Measure the generated error.\n","- Step 5: *Back-Porpagation*: from right to left, the error is back-propagated. Update the weights according to how much they are responsible for the error. The learning rate decides by how much we update the weights.\n","- Step 6: Repeat Steps 1-5 and update the weights after each observation (Reinforcement Learning). Or: Repeat Steps 1 tp 5 but update the weights only after a batch of observations (Batch Learning)\n","- Step 7: When the whole training set passed through the ANN, that makes an **epoch**. Redo more epochs.\n"],"metadata":{"id":"IFzX4THxdVCP"}},{"cell_type":"markdown","source":["- Geodemographic segmentation model"],"metadata":{"id":"NfOKHBS_ek3O"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"V_Popnl53tRv","executionInfo":{"status":"ok","timestamp":1676668682810,"user_tz":300,"elapsed":4084,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}}},"outputs":[],"source":["# Import the libraries\n","\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf"]},{"cell_type":"code","source":["tf.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"QTxQsMJWDwWI","executionInfo":{"status":"ok","timestamp":1676668682812,"user_tz":300,"elapsed":20,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}},"outputId":"2b9d1ac5-ee1f-42fe-ca3f-d442170108e6"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.11.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["# Part1: Data Preprocessing\n","# Importing the dataset\n","dataset = pd.read_csv(\"Churn_Modelling.csv\")\n","X = dataset.iloc[:,3:-1].values\n","y = dataset.iloc[:,-1].values"],"metadata":{"id":"_-iCODAaCRwg","executionInfo":{"status":"ok","timestamp":1676668682813,"user_tz":300,"elapsed":17,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGUZk7ESE-Pj","executionInfo":{"status":"ok","timestamp":1676668682814,"user_tz":300,"elapsed":17,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}},"outputId":"205728f5-8e22-406d-c2e9-d8f401dec26e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[[619 'France' 'Female' ... 1 1 101348.88]\n"," [608 'Spain' 'Female' ... 0 1 112542.58]\n"," [502 'France' 'Female' ... 1 0 113931.57]\n"," ...\n"," [709 'France' 'Female' ... 0 1 42085.58]\n"," [772 'Germany' 'Male' ... 1 0 92888.52]\n"," [792 'France' 'Female' ... 1 0 38190.78]]\n"]}]},{"cell_type":"code","source":["print(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5m0f1VlvFCsa","executionInfo":{"status":"ok","timestamp":1676668683094,"user_tz":300,"elapsed":293,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}},"outputId":"06c7df5e-6262-4b9f-d259-6bb9d073c438"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 0 1 ... 1 1 0]\n"]}]},{"cell_type":"code","source":["# Encoding categorical data\n","# Label encoding the \"Gender\" column\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","X[:, 2] = le.fit_transform(X[:, 2])"],"metadata":{"id":"Q2qA79LaDRwh","executionInfo":{"status":"ok","timestamp":1676668685014,"user_tz":300,"elapsed":1562,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A1cgmqw4FhzD","executionInfo":{"status":"ok","timestamp":1676668686657,"user_tz":300,"elapsed":3,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}},"outputId":"9b2ebac2-c73a-47e6-9428-115daf59c5ee"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[[619 'France' 0 ... 1 1 101348.88]\n"," [608 'Spain' 0 ... 0 1 112542.58]\n"," [502 'France' 0 ... 1 0 113931.57]\n"," ...\n"," [709 'France' 0 ... 0 1 42085.58]\n"," [772 'Germany' 1 ... 1 0 92888.52]\n"," [792 'France' 0 ... 1 0 38190.78]]\n"]}]},{"cell_type":"code","source":["# One Hot Encoding the \"Geograpgy\" column\n","from sklearn.compose import ColumnTransformer\n","from sklearn.preprocessing import OneHotEncoder\n","ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n","X = np.array(ct.fit_transform(X))"],"metadata":{"id":"o1cBuuFjDRqJ","executionInfo":{"status":"ok","timestamp":1676668688112,"user_tz":300,"elapsed":234,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOHpDY2gGoRN","executionInfo":{"status":"ok","timestamp":1676668689582,"user_tz":300,"elapsed":6,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}},"outputId":"48928c75-c11e-4c6c-d68f-3f2f87506bda"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.0 0.0 0.0 ... 1 1 101348.88]\n"," [0.0 0.0 1.0 ... 0 1 112542.58]\n"," [1.0 0.0 0.0 ... 1 0 113931.57]\n"," ...\n"," [1.0 0.0 0.0 ... 0 1 42085.58]\n"," [0.0 1.0 0.0 ... 1 0 92888.52]\n"," [1.0 0.0 0.0 ... 1 0 38190.78]]\n"]}]},{"cell_type":"code","source":["print(X[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"erGkoEiZHC6U","executionInfo":{"status":"ok","timestamp":1676668693250,"user_tz":300,"elapsed":117,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}},"outputId":"829c57e7-9405-4d20-e698-4d1e1d2f72b0"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[1.0 0.0 0.0 619 0 42 2 0.0 1 1 1 101348.88]\n"]}]},{"cell_type":"code","source":["# Splitting the dataset into Training and testing set\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X,y,\n","                                                    test_size=0.2,\n","                                                    random_state=0)"],"metadata":{"id":"7mpP5oV8CRrT","executionInfo":{"status":"ok","timestamp":1676668694637,"user_tz":300,"elapsed":149,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Feature scaling : This step is compulsary for \n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","\n","X_train_scaled = sc.fit_transform(X_train)\n","# We don't fit_transform again as that would cause data leakage\n","X_test_scaled = sc.transform(X_test)"],"metadata":{"id":"I-rNDM10CRoz","executionInfo":{"status":"ok","timestamp":1676668695207,"user_tz":300,"elapsed":128,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Part2: Building the ANN"],"metadata":{"id":"jFo3jHSOCRmh","executionInfo":{"status":"ok","timestamp":1676668696114,"user_tz":300,"elapsed":3,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Initialize the ANN\n","ann = tf.keras.models.Sequential()"],"metadata":{"id":"RPx5YUpcCuuT","executionInfo":{"status":"ok","timestamp":1676668696692,"user_tz":300,"elapsed":158,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Adding the input layer and the first hidden layer\n","ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"],"metadata":{"id":"Vs-YU_hrCur6","executionInfo":{"status":"ok","timestamp":1676668697391,"user_tz":300,"elapsed":111,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Adding the second hidden layer\n","ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"],"metadata":{"id":"GX93HIrtCupT","executionInfo":{"status":"ok","timestamp":1676668698516,"user_tz":300,"elapsed":134,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Adding the output layer. Binary unit=1,\n","# but if we have A,B,C as y, we use unit = 2 \n","# one hot encode these i.e A = 1 0 0, B = 0 1 0, C = 0 0 1\n","# sigmoid activation function for output layer as that will return probabilty\n","# for non binary we also set activation as softmax\n","ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"],"metadata":{"id":"_1TOY9XjCum_","executionInfo":{"status":"ok","timestamp":1676668699078,"user_tz":300,"elapsed":6,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# Part3: Training the ANN"],"metadata":{"id":"H0oOLuACCuko","executionInfo":{"status":"ok","timestamp":1676668700887,"user_tz":300,"elapsed":103,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# Compiling the ANN\n","# for non binary we use loss = categorical_crossentropy\n","ann.compile(optimizer='adam', loss='binary_crossentropy', metrics= ['accuracy'])"],"metadata":{"id":"0guvwPHOCuiH","executionInfo":{"status":"ok","timestamp":1676668701721,"user_tz":300,"elapsed":120,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# Training the ANN on the Training set\n","ann.fit(X_train_scaled, y_train, batch_size = 32, epochs=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FpLYsDCTCRj_","executionInfo":{"status":"ok","timestamp":1676668834450,"user_tz":300,"elapsed":36714,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}},"outputId":"59445475-31ce-46bb-ad6e-666d4fd47ff8"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","250/250 [==============================] - 1s 1ms/step - loss: 0.5319 - accuracy: 0.7928\n","Epoch 2/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.7960\n","Epoch 3/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7960\n","Epoch 4/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.7960\n","Epoch 5/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.7965\n","Epoch 6/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4240 - accuracy: 0.8083\n","Epoch 7/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4208 - accuracy: 0.8181\n","Epoch 8/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4181 - accuracy: 0.8234\n","Epoch 9/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4158 - accuracy: 0.8251\n","Epoch 10/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4130 - accuracy: 0.8281\n","Epoch 11/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4101 - accuracy: 0.8284\n","Epoch 12/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4068 - accuracy: 0.8306\n","Epoch 13/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.4030 - accuracy: 0.8330\n","Epoch 14/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3990 - accuracy: 0.8356\n","Epoch 15/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3948 - accuracy: 0.8375\n","Epoch 16/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8374\n","Epoch 17/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8397\n","Epoch 18/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3844 - accuracy: 0.8407\n","Epoch 19/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3818 - accuracy: 0.8404\n","Epoch 20/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8395\n","Epoch 21/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3770 - accuracy: 0.8413\n","Epoch 22/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3754 - accuracy: 0.8418\n","Epoch 23/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3726 - accuracy: 0.8430\n","Epoch 24/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3702 - accuracy: 0.8450\n","Epoch 25/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3674 - accuracy: 0.8481\n","Epoch 26/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3651 - accuracy: 0.8501\n","Epoch 27/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3630 - accuracy: 0.8525\n","Epoch 28/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3605 - accuracy: 0.8524\n","Epoch 29/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3586 - accuracy: 0.8536\n","Epoch 30/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8551\n","Epoch 31/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3544 - accuracy: 0.8564\n","Epoch 32/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3520 - accuracy: 0.8570\n","Epoch 33/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.8584\n","Epoch 34/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3478 - accuracy: 0.8581\n","Epoch 35/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3462 - accuracy: 0.8591\n","Epoch 36/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3446 - accuracy: 0.8600\n","Epoch 37/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3435 - accuracy: 0.8608\n","Epoch 38/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3427 - accuracy: 0.8600\n","Epoch 39/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.8600\n","Epoch 40/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3407 - accuracy: 0.8610\n","Epoch 41/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3402 - accuracy: 0.8614\n","Epoch 42/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.8618\n","Epoch 43/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3393 - accuracy: 0.8618\n","Epoch 44/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3388 - accuracy: 0.8614\n","Epoch 45/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8606\n","Epoch 46/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8627\n","Epoch 47/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8633\n","Epoch 48/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8614\n","Epoch 49/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8619\n","Epoch 50/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8631\n","Epoch 51/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3363 - accuracy: 0.8641\n","Epoch 52/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8622\n","Epoch 53/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8604\n","Epoch 54/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8627\n","Epoch 55/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8631\n","Epoch 56/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8639\n","Epoch 57/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8618\n","Epoch 58/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8625\n","Epoch 59/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8635\n","Epoch 60/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8620\n","Epoch 61/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8606\n","Epoch 62/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8624\n","Epoch 63/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8625\n","Epoch 64/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8643\n","Epoch 65/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8624\n","Epoch 66/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8624\n","Epoch 67/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8631\n","Epoch 68/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8624\n","Epoch 69/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8636\n","Epoch 70/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8618\n","Epoch 71/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8619\n","Epoch 72/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8610\n","Epoch 73/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8630\n","Epoch 74/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8631\n","Epoch 75/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8626\n","Epoch 76/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8625\n","Epoch 77/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8626\n","Epoch 78/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8639\n","Epoch 79/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8621\n","Epoch 80/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8621\n","Epoch 81/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8635\n","Epoch 82/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8619\n","Epoch 83/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8624\n","Epoch 84/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8624\n","Epoch 85/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8631\n","Epoch 86/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8637\n","Epoch 87/100\n","250/250 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8636\n","Epoch 88/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8602\n","Epoch 89/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8616\n","Epoch 90/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8622\n","Epoch 91/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8639\n","Epoch 92/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8636\n","Epoch 93/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8624\n","Epoch 94/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8625\n","Epoch 95/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8621\n","Epoch 96/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8630\n","Epoch 97/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8639\n","Epoch 98/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8626\n","Epoch 99/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8620\n","Epoch 100/100\n","250/250 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8635\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fda3fb55c40>"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["# Part 4: Making the predicions and evaluating the model"],"metadata":{"id":"BPAYBDXKCRhb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Observation**\n","\n","Use our ANN model to predict if the customer with the following informations will leave the bank: \n","\n","Geography: France\n","\n","Credit Score: 600\n","\n","Gender: Male\n","\n","Age: 40 years old\n","\n","Tenure: 3 years\n","\n","Balance: \\$ 60000\n","\n","Number of Products: 2\n","\n","Does this customer have a credit card? Yes\n","\n","Is this customer an Active Member: Yes\n","\n","Estimated Salary: \\$ 50000\n","\n","So, should we say goodbye to that customer?"],"metadata":{"id":"sVPYsD4GQE7B"}},{"cell_type":"code","source":["# Predicting the result of a single observation\n","print(f\"Probability: {ann.predict(sc.transform([[1,0,0,600,1,40,3,60000,2,1,1,50000]]))}\")\n","print(f\"Outcome (False/True): {ann.predict(sc.transform([[1,0,0,600,1,40,3,60000,2,1,1,50000]]))>0.5}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CdfZg-TtCRfE","executionInfo":{"status":"ok","timestamp":1676669522921,"user_tz":300,"elapsed":569,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}},"outputId":"4b3f1c5e-2302-4dbf-d8e4-548045003669"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 46ms/step\n","Probability: [[0.0294814]]\n","1/1 [==============================] - 0s 39ms/step\n","Outcome (False/True): [[False]]\n"]}]},{"cell_type":"code","source":["# Predicting the test set results\n","y_pred = ann.predict(X_test_scaled)\n","# To get True/False or 0/1\n","y_pred = y_pred > 0.5\n","print(np.concatenate(\n","    (y_pred.reshape(len(y_pred),1),\n","     y_test.reshape(len(y_test),1)),\n","     1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XCuTFAmmDKG1","executionInfo":{"status":"ok","timestamp":1676669653165,"user_tz":300,"elapsed":531,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}},"outputId":"5c66ce7a-6b95-4857-e0de-1884b66b8071"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["63/63 [==============================] - 0s 3ms/step\n","[[0 0]\n"," [0 1]\n"," [0 0]\n"," ...\n"," [0 0]\n"," [0 0]\n"," [0 0]]\n"]}]},{"cell_type":"code","source":["# Making the Confusion Matrix and calculating accuracy\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","cm = confusion_matrix(y_test,y_pred)\n","acc = accuracy_score(y_test, y_pred)\n","print(f\"Confusion Matrix:\\n {cm}\\n Accuracy: {acc}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WGUYodSvDKEs","executionInfo":{"status":"ok","timestamp":1676669833707,"user_tz":300,"elapsed":192,"user":{"displayName":"Sandeep Solanki","userId":"01458181257464856214"}},"outputId":"9d0baec7-6bcc-4bce-a592-827ab83d403f"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix:\n"," [[1511   84]\n"," [ 202  203]]\n"," Accuracy: 0.857\n"]}]}]}